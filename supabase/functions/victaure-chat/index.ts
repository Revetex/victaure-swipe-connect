
import { serve } from "https://deno.land/std@0.168.0/http/server.ts";
import { Configuration, OpenAIApi } from 'https://esm.sh/openai@3.1.0';
import { corsHeaders } from '../_shared/cors.ts';

const TIMEOUT_DURATION = 25000; // 25 secondes

interface Message {
  role: "system" | "user" | "assistant";
  content: string;
}

interface RequestBody {
  messages: Message[];
  userId?: string;
  userProfile?: {
    full_name?: string;
  };
}

console.log("Starting victaure-chat function with timeout protection");

const openAIKey = Deno.env.get('OPENAI_API_KEY');
if (!openAIKey) {
  console.error("OPENAI_API_KEY is not set");
  throw new Error("OPENAI_API_KEY is not set");
}

const configuration = new Configuration({
  apiKey: openAIKey,
});

const openai = new OpenAIApi(configuration);

// Fonction avec timeout
async function fetchWithTimeout(promise: Promise<any>, timeout: number) {
  let timeoutId: number;
  
  const timeoutPromise = new Promise((_, reject) => {
    timeoutId = setTimeout(() => {
      reject(new Error(`Operation timed out after ${timeout}ms`));
    }, timeout);
  });

  try {
    const result = await Promise.race([promise, timeoutPromise]);
    clearTimeout(timeoutId);
    return result;
  } catch (error) {
    clearTimeout(timeoutId);
    throw error;
  }
}

serve(async (req) => {
  console.log(`[${new Date().toISOString()}] Request received:`, req.method);

  if (req.method === 'OPTIONS') {
    return new Response('ok', { headers: corsHeaders });
  }

  try {
    const { messages, userId, userProfile } = await req.json() as RequestBody;
    console.log(`[${new Date().toISOString()}] Processing request for ${userProfile?.full_name || 'anonymous'}`);

    if (!messages?.length) {
      throw new Error("Messages array is required and must not be empty");
    }

    // Préparation du contexte avec limite de taille
    const systemContext = (userId && userProfile?.full_name)
      ? `${messages[0].content}\nVous parlez à ${userProfile.full_name}.`.slice(0, 1000)
      : messages[0].content.slice(0, 1000);

    // Préparation des messages avec limite de taille
    const processedMessages = messages.map(m => ({
      role: m.role,
      content: m.content.slice(0, 1000) // Limite la taille de chaque message
    }));

    console.log(`[${new Date().toISOString()}] Calling OpenAI API`);

    const completionPromise = openai.createChatCompletion({
      model: "gpt-3.5-turbo",
      messages: processedMessages,
      temperature: 0.7,
      max_tokens: 300, // Réduit pour éviter les timeouts
      frequency_penalty: 0.5,
      presence_penalty: 0.5,
      timeout: 20000, // 20 secondes timeout pour l'API OpenAI
    });

    const completion = await fetchWithTimeout(completionPromise, TIMEOUT_DURATION);

    console.log(`[${new Date().toISOString()}] OpenAI API responded successfully`);

    if (!completion.data.choices?.length) {
      throw new Error("No response generated by OpenAI");
    }

    return new Response(
      JSON.stringify({ choices: completion.data.choices }),
      {
        headers: { ...corsHeaders, 'Content-Type': 'application/json' },
        status: 200,
      }
    );

  } catch (error) {
    console.error(`[${new Date().toISOString()}] Error:`, error);

    const errorResponse = {
      error: {
        message: error instanceof Error ? error.message : "An unknown error occurred",
        name: error instanceof Error ? error.name : "UnknownError",
        timestamp: new Date().toISOString()
      }
    };

    return new Response(
      JSON.stringify(errorResponse),
      {
        headers: { ...corsHeaders, 'Content-Type': 'application/json' },
        status: 500,
      }
    );
  }
});
